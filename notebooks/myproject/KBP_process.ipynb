{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f9ab189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_infix_regex\n",
    "from spacy.lang.char_classes import ALPHA, ALPHA_LOWER, ALPHA_UPPER, HYPHENS\n",
    "from spacy.lang.char_classes import CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS\n",
    "from spacy.util import compile_infix_regex\n",
    "from spacy.matcher import Matcher\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2d8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize spacy tokenizer\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Modify tokenizer infix patterns\n",
    "infixes = (\n",
    "    LIST_ELLIPSES\n",
    "    + LIST_ICONS\n",
    "    + [\n",
    "#         r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n",
    "        r\"(?<=[{al}{q}])\\.(?=[{au}{q}])\".format(\n",
    "            al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n",
    "        ),\n",
    "        r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
    "#         r\"(?<=[{a}])(?:{h})(?=[{a}])\".format(a=ALPHA, h=HYPHENS),\n",
    "#         r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
    "        r\"(?<=[{a}0-9])[:<>=](?=[{a}])\".format(a=ALPHA),\n",
    "    ]\n",
    ")\n",
    "\n",
    "infix_re = compile_infix_regex(infixes)\n",
    "nlp.tokenizer.infix_finditer = infix_re.finditer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3959266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(exp, res, sentid, sent2query, only_ent, ner_dict, re_dict, re2ner, hard_rule):\n",
    "    exp_text = exp['sentText']\n",
    "    text_doc = nlp(exp_text)\n",
    "    exp_tokens = [unidecode.unidecode(tok.text) for tok in text_doc if tok.text != '\\r\\n']\n",
    "    re_count = 0\n",
    "    sent_res = []\n",
    "    entMentions = [item for idx, item in enumerate(exp['entityMentions']) if item not in exp['entityMentions'][idx + 1:]]\n",
    "    reMentions = [item for idx, item in enumerate(exp['relationMentions']) if item not in exp['relationMentions'][idx + 1:]]\n",
    "    \n",
    "    for ins_id, NER in enumerate(entMentions):\n",
    "        query, ner_tag = NER['text'], NER['label']\n",
    "        query_doc = nlp(query)\n",
    "        query_tokens = [tok.text for tok in query_doc]\n",
    "        query_ids = [idx for idx, tok in enumerate(exp_tokens) if tok == unidecode.unidecode(query_tokens[0])]\n",
    "        query_id = None\n",
    "        \n",
    "        for idx in query_ids:\n",
    "            if idx not in sent2query[sentid]:\n",
    "                query_id = idx\n",
    "                break\n",
    "        \n",
    "        if query_id is not None:\n",
    "            if ner_tag != 'None':\n",
    "                ner_dict[ner_tag] = ner_dict.get(ner_tag, 0) + 1\n",
    "            tokens = np.array([\"O\"]*len(exp_tokens), dtype='object')\n",
    "            tokens[query_id] = \"B-\" + ner_tag\n",
    "            tokens[query_id+1:query_id+len(query_tokens)] = \"I-\" + ner_tag\n",
    "            sent2query[sentid].append(query_id)\n",
    "\n",
    "            for RE in reMentions:\n",
    "                target, re_tag = RE['em2Text'], RE['label']\n",
    "                if (RE['em1Text'] == query) and (re_tag != 'None') and (ner_tag == hard_rule[re_tag]): # hard rule\n",
    "                    re_dict[re_tag] = re_dict.get(re_tag, 0) + 1\n",
    "                    re2ner[re_tag].append(ner_tag)\n",
    "                    target_doc = nlp(target)\n",
    "                    target_tokens = [tok.text for tok in target_doc]\n",
    "                    target_ids = [idx for idx, tok in enumerate(exp_tokens) if tok == unidecode.unidecode(target_tokens[0])]\n",
    "                    target_id = None\n",
    "\n",
    "                    for idx in target_ids:\n",
    "                        if idx != query_id:\n",
    "                            target_id = idx\n",
    "                            break\n",
    "\n",
    "                    if target_id is not None:\n",
    "                        re_count += 1\n",
    "                        tokens[target_id] = \"B-\" + re_tag\n",
    "                        tokens[target_id+1:target_id+len(target_tokens)] = \"I-\" + re_tag\n",
    "#                         print(\"\\ttarget_id: {}, target_entity: {}, target_tag: {}\".format(target_id, target, re_tag))\n",
    "                        \n",
    "            ins_ID = len(res)+len(sent_res)\n",
    "            sent_res.append({\n",
    "                \"tokens\":exp_tokens, \"ner_tags\":tokens.tolist(), \n",
    "                \"query_ids\":query_id, \"sentID\":sentid, \"instanceID\":ins_ID,\n",
    "            })\n",
    "        \n",
    "    # check query entity tag\n",
    "    P = False\n",
    "    if only_ent:\n",
    "        if re_count == 0 and not P: # not contain relations\n",
    "            res += sent_res\n",
    "    else:\n",
    "        if not P:\n",
    "            res += sent_res\n",
    "        \n",
    "\n",
    "def process_data(dataset, hard_rule, only_ent=False):\n",
    "    res = []\n",
    "    sent2query = defaultdict(list)\n",
    "    re_dict = defaultdict(int)\n",
    "    ner_dict = defaultdict(int)\n",
    "    re2ner = defaultdict(list)\n",
    "    for i, instance in tqdm(enumerate(dataset)):\n",
    "#         try:\n",
    "#             process(instance, res, i, sent2query, only_ent=only_ent)\n",
    "#         except:\n",
    "#             pass\n",
    "        process(instance, res, i, sent2query, only_ent, ner_dict, re_dict, re2ner, hard_rule)\n",
    "    \n",
    "    return res, ner_dict, re_dict, re2ner\n",
    "\n",
    "\n",
    "def saving(f_path, res):\n",
    "    with open(f_path, 'w') as f: \n",
    "        for value in res:\n",
    "            f.write(json.dumps(value))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4b68be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 56.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235982 395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235982it [1:05:55, 59.65it/s]\n"
     ]
    }
   ],
   "source": [
    "DIR = 'NYT'\n",
    "train_json = \"train.json\"\n",
    "test_json = \"test.json\"\n",
    "# train_file = os.path.join(DIR, train_json)\n",
    "# test_file = os.path.join(DIR, test_json)\n",
    "\n",
    "def load_data(src_dir=\".\", file_name=\"train.json\"):\n",
    "    raw_json = os.path.join(src_dir, file_name)\n",
    "    file = open(raw_json, 'r')\n",
    "    sentences = file.readlines()\n",
    "    return [json.loads(line) for line in sentences]\n",
    "\n",
    "train_data = load_data(DIR, train_json)\n",
    "test_data = load_data(DIR, test_json)\n",
    "print(len(train_data), len(test_data))\n",
    "\n",
    "# test_processed_data, ner_dict_test, re_dict_test, re2ner_test = process_data(test_data)\n",
    "# saving(test_file, test_processed_data)\n",
    "train_processed_data_filtered, ner_dict_train_filtered, re_dict_train_filtered, re2ner_train_filtered = process_data(train_data, hard_rule)\n",
    "# saving(train_file, train_processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a494ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.path.join(DIR, \"train_NYT_preprocessed.json\")\n",
    "saving(train_file, train_processed_data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db55c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'/people/person/nationality': 7767,\n",
       "             '/people/deceased_person/place_of_death': 1965,\n",
       "             '/location/country/capital': 7933,\n",
       "             '/location/location/contains': 52950,\n",
       "             '/people/person/children': 529,\n",
       "             '/people/person/place_of_birth': 3218,\n",
       "             '/people/person/place_lived': 7359,\n",
       "             '/location/administrative_division/country': 6276,\n",
       "             '/location/country/administrative_divisions': 6621,\n",
       "             '/business/person/company': 5623,\n",
       "             '/location/neighborhood/neighborhood_of': 5546,\n",
       "             '/business/company/place_founded': 424,\n",
       "             '/business/company/founders': 849,\n",
       "             '/sports/sports_team/location': 226,\n",
       "             '/sports/sports_team_location/teams': 225,\n",
       "             '/business/company_shareholder/major_shareholder_of': 296,\n",
       "             '/business/company/major_shareholders': 308,\n",
       "             '/people/person/ethnicity': 21,\n",
       "             '/people/ethnicity/people': 21,\n",
       "             '/business/company/advisors': 49,\n",
       "             '/people/person/religion': 72,\n",
       "             '/people/ethnicity/geographic_distribution': 37,\n",
       "             '/people/person/profession': 2,\n",
       "             '/business/company/industry': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_dict_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1732ed00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'PERSON': 303739, 'LOCATION': 403820, 'ORGANIZATION': 93434})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dict_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e08311f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/people/person/nationality: {'PERSON': 7654, 'LOCATION': 83, 'ORGANIZATION': 30}\n",
      "/people/deceased_person/place_of_death: {'PERSON': 1932, 'ORGANIZATION': 23, 'LOCATION': 10}\n",
      "/location/country/capital: {'LOCATION': 7912, 'PERSON': 20, 'ORGANIZATION': 1}\n",
      "/location/location/contains: {'LOCATION': 52676, 'ORGANIZATION': 184, 'PERSON': 90}\n",
      "/people/person/children: {'PERSON': 525, 'ORGANIZATION': 4}\n",
      "/people/person/place_of_birth: {'PERSON': 3149, 'ORGANIZATION': 53, 'LOCATION': 16}\n",
      "/people/person/place_lived: {'PERSON': 7274, 'ORGANIZATION': 70, 'LOCATION': 15}\n",
      "/location/administrative_division/country: {'LOCATION': 6185, 'ORGANIZATION': 60, 'PERSON': 31}\n",
      "/location/country/administrative_divisions: {'LOCATION': 6619, 'ORGANIZATION': 2}\n",
      "/business/person/company: {'PERSON': 5604, 'ORGANIZATION': 14, 'LOCATION': 5}\n",
      "/location/neighborhood/neighborhood_of: {'LOCATION': 5191, 'ORGANIZATION': 164, 'PERSON': 191}\n",
      "/business/company/place_founded: {'ORGANIZATION': 388, 'PERSON': 21, 'LOCATION': 15}\n",
      "/business/company/founders: {'LOCATION': 15, 'ORGANIZATION': 822, 'PERSON': 12}\n",
      "/sports/sports_team/location: {'ORGANIZATION': 225, 'LOCATION': 1}\n",
      "/sports/sports_team_location/teams: {'LOCATION': 217, 'ORGANIZATION': 8}\n",
      "/business/company_shareholder/major_shareholder_of: {'PERSON': 271, 'LOCATION': 25}\n",
      "/business/company/major_shareholders: {'ORGANIZATION': 305, 'LOCATION': 3}\n",
      "/people/person/ethnicity: {'PERSON': 21}\n",
      "/people/ethnicity/people: {'LOCATION': 11, 'PERSON': 9, 'ORGANIZATION': 1}\n",
      "/business/company/advisors: {'ORGANIZATION': 49}\n",
      "/people/person/religion: {'PERSON': 71, 'ORGANIZATION': 1}\n",
      "/people/ethnicity/geographic_distribution: {'LOCATION': 37}\n",
      "/people/person/profession: {'PERSON': 2}\n",
      "/business/company/industry: {'ORGANIZATION': 1}\n"
     ]
    }
   ],
   "source": [
    "re2ner_train_count = defaultdict(dict)\n",
    "\n",
    "for re in re2ner_train:\n",
    "    re2ner_train_count[re] = Counter(re2ner_train[re])\n",
    "    print(\"{}: {}\".format(re, dict(re2ner_train_count[re])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "368beb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/people/person/nationality: {'PERSON': 7654}\n",
      "/people/deceased_person/place_of_death: {'PERSON': 1932}\n",
      "/location/country/capital: {'LOCATION': 7912}\n",
      "/location/location/contains: {'LOCATION': 52676}\n",
      "/people/person/children: {'PERSON': 525}\n",
      "/people/person/place_of_birth: {'PERSON': 3149}\n",
      "/people/person/place_lived: {'PERSON': 7274}\n",
      "/location/administrative_division/country: {'LOCATION': 6185}\n",
      "/location/country/administrative_divisions: {'LOCATION': 6619}\n",
      "/business/person/company: {'PERSON': 5604}\n",
      "/location/neighborhood/neighborhood_of: {'LOCATION': 5191}\n",
      "/business/company/place_founded: {'ORGANIZATION': 388}\n",
      "/sports/sports_team/location: {'ORGANIZATION': 225}\n",
      "/sports/sports_team_location/teams: {'LOCATION': 217}\n",
      "/business/company_shareholder/major_shareholder_of: {'PERSON': 271}\n",
      "/business/company/major_shareholders: {'ORGANIZATION': 305}\n",
      "/business/company/founders: {'ORGANIZATION': 822}\n",
      "/people/person/ethnicity: {'PERSON': 21}\n",
      "/people/ethnicity/people: {'LOCATION': 11}\n",
      "/business/company/advisors: {'ORGANIZATION': 49}\n",
      "/people/person/religion: {'PERSON': 71}\n",
      "/people/ethnicity/geographic_distribution: {'LOCATION': 37}\n",
      "/people/person/profession: {'PERSON': 2}\n",
      "/business/company/industry: {'ORGANIZATION': 1}\n"
     ]
    }
   ],
   "source": [
    "# filtered\n",
    "re2ner_train_count_filtered = defaultdict(dict)\n",
    "\n",
    "for re in re2ner_train_filtered:\n",
    "    re2ner_train_count_filtered[re] = Counter(re2ner_train_filtered[re])\n",
    "    print(\"{}: {}\".format(re, dict(re2ner_train_count_filtered[re])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2c6a363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(str,\n",
       "            {'/people/person/nationality': 'PERSON',\n",
       "             '/people/deceased_person/place_of_death': 'PERSON',\n",
       "             '/location/country/capital': 'LOCATION',\n",
       "             '/location/location/contains': 'LOCATION',\n",
       "             '/people/person/children': 'PERSON',\n",
       "             '/people/person/place_of_birth': 'PERSON',\n",
       "             '/people/person/place_lived': 'PERSON',\n",
       "             '/location/administrative_division/country': 'LOCATION',\n",
       "             '/location/country/administrative_divisions': 'LOCATION',\n",
       "             '/business/person/company': 'PERSON',\n",
       "             '/location/neighborhood/neighborhood_of': 'LOCATION',\n",
       "             '/business/company/place_founded': 'ORGANIZATION',\n",
       "             '/business/company/founders': 'ORGANIZATION',\n",
       "             '/sports/sports_team/location': 'ORGANIZATION',\n",
       "             '/sports/sports_team_location/teams': 'LOCATION',\n",
       "             '/business/company_shareholder/major_shareholder_of': 'PERSON',\n",
       "             '/business/company/major_shareholders': 'ORGANIZATION',\n",
       "             '/people/person/ethnicity': 'PERSON',\n",
       "             '/people/ethnicity/people': 'LOCATION',\n",
       "             '/business/company/advisors': 'ORGANIZATION',\n",
       "             '/people/person/religion': 'PERSON',\n",
       "             '/people/ethnicity/geographic_distribution': 'LOCATION',\n",
       "             '/people/person/profession': 'PERSON',\n",
       "             '/business/company/industry': 'ORGANIZATION'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define hard relation-entity rules\n",
    "hard_rule = defaultdict(str)\n",
    "\n",
    "for re in re2ner_train_count:\n",
    "    hard_rule[re] = re2ner_train_count[re].most_common()[0][0]\n",
    "    \n",
    "hard_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f87f8414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'/people/person/place_lived': 40,\n",
       "             '/location/country/capital': 2,\n",
       "             '/location/location/contains': 179,\n",
       "             '/location/administrative_division/country': 108,\n",
       "             '/business/person/company': 37,\n",
       "             '/people/person/nationality': 23,\n",
       "             '/people/person/children': 2,\n",
       "             '/business/company/founders': 5,\n",
       "             '/location/neighborhood/neighborhood_of': 1,\n",
       "             '/location/country/administrative_divisions': 3,\n",
       "             '/people/person/place_of_birth': 1,\n",
       "             '/people/deceased_person/place_of_death': 2})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_dict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a746d65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'PERSON': 280, 'LOCATION': 940, 'ORGANIZATION': 141})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d8c0d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/people/person/place_lived: {'PERSON': 40}\n",
      "/location/country/capital: {'LOCATION': 2}\n",
      "/location/location/contains: {'LOCATION': 178, 'PERSON': 1}\n",
      "/location/administrative_division/country: {'LOCATION': 108}\n",
      "/business/person/company: {'PERSON': 37}\n",
      "/people/person/nationality: {'PERSON': 23}\n",
      "/people/person/children: {'PERSON': 2}\n",
      "/business/company/founders: {'ORGANIZATION': 5}\n",
      "/location/neighborhood/neighborhood_of: {'LOCATION': 1}\n",
      "/location/country/administrative_divisions: {'LOCATION': 3}\n",
      "/people/person/place_of_birth: {'PERSON': 1}\n",
      "/people/deceased_person/place_of_death: {'PERSON': 2}\n"
     ]
    }
   ],
   "source": [
    "re2ner_test_count = defaultdict(dict)\n",
    "\n",
    "for re in re2ner_test:\n",
    "    re2ner_test_count[re] = Counter(re2ner_test[re])\n",
    "    print(\"{}: {}\".format(re, dict(re2ner_test_count[re])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ac35894",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    \"B-/business/company/advisors\": 0,\n",
    "    \"B-/business/company/founders\": 1,\n",
    "    \"B-/business/company/industry\": 2,\n",
    "    \"B-/business/company/major_shareholders\": 3,\n",
    "    \"B-/business/company/place_founded\": 4,\n",
    "    \"B-/business/company_shareholder/major_shareholder_of\": 5,\n",
    "    \"B-/business/person/company\": 6,\n",
    "    \"B-/location/administrative_division/country\": 7,\n",
    "    \"B-/location/country/administrative_divisions\": 8,\n",
    "    \"B-/location/country/capital\": 9,\n",
    "    \"B-/location/location/contains\": 10,\n",
    "    \"B-/location/neighborhood/neighborhood_of\": 11,\n",
    "    \"B-/people/deceased_person/place_of_death\": 12,\n",
    "    \"B-/people/ethnicity/geographic_distribution\": 13,\n",
    "    \"B-/people/ethnicity/people\": 14,\n",
    "    \"B-/people/person/children\": 15,\n",
    "    \"B-/people/person/ethnicity\": 16,\n",
    "    \"B-/people/person/nationality\": 17,\n",
    "    \"B-/people/person/place_lived\": 18,\n",
    "    \"B-/people/person/place_of_birth\": 19,\n",
    "    \"B-/people/person/religion\": 20,\n",
    "    \"B-/sports/sports_team/location\": 21,\n",
    "    \"B-/sports/sports_team_location/teams\": 22,\n",
    "    \"B-LOCATION\": 23,\n",
    "    \"B-ORGANIZATION\": 24,\n",
    "    \"B-PERSON\": 25,\n",
    "    \"I-/business/company/advisors\": 26,\n",
    "    \"I-/business/company/founders\": 27,\n",
    "    \"I-/business/company/industry\": 28,\n",
    "    \"I-/business/company/major_shareholders\": 29,\n",
    "    \"I-/business/company/place_founded\": 30,\n",
    "    \"I-/business/company_shareholder/major_shareholder_of\": 31,\n",
    "    \"I-/business/person/company\": 32,\n",
    "    \"I-/location/administrative_division/country\": 33,\n",
    "    \"I-/location/country/administrative_divisions\": 34,\n",
    "    \"I-/location/country/capital\": 35,\n",
    "    \"I-/location/location/contains\": 36,\n",
    "    \"I-/location/neighborhood/neighborhood_of\": 37,\n",
    "    \"I-/people/deceased_person/place_of_death\": 38,\n",
    "    \"I-/people/ethnicity/people\": 39,\n",
    "    \"I-/people/person/children\": 40,\n",
    "    \"I-/people/person/nationality\": 41,\n",
    "    \"I-/people/person/place_lived\": 42,\n",
    "    \"I-/people/person/place_of_birth\": 43,\n",
    "    \"I-/people/person/religion\": 44,\n",
    "    \"I-/sports/sports_team/location\": 45,\n",
    "    \"I-/sports/sports_team_location/teams\": 46,\n",
    "    \"I-LOCATION\": 47,\n",
    "    \"I-ORGANIZATION\": 48,\n",
    "    \"I-PERSON\": 49,\n",
    "    \"O\": 50\n",
    "}\n",
    "\n",
    "id2label = {\n",
    "    \"0\": \"B-/business/company/advisors\",\n",
    "    \"1\": \"B-/business/company/founders\",\n",
    "    \"2\": \"B-/business/company/industry\",\n",
    "    \"3\": \"B-/business/company/major_shareholders\",\n",
    "    \"4\": \"B-/business/company/place_founded\",\n",
    "    \"5\": \"B-/business/company_shareholder/major_shareholder_of\",\n",
    "    \"6\": \"B-/business/person/company\",\n",
    "    \"7\": \"B-/location/administrative_division/country\",\n",
    "    \"8\": \"B-/location/country/administrative_divisions\",\n",
    "    \"9\": \"B-/location/country/capital\",\n",
    "    \"10\": \"B-/location/location/contains\",\n",
    "    \"11\": \"B-/location/neighborhood/neighborhood_of\",\n",
    "    \"12\": \"B-/people/deceased_person/place_of_death\",\n",
    "    \"13\": \"B-/people/ethnicity/geographic_distribution\",\n",
    "    \"14\": \"B-/people/ethnicity/people\",\n",
    "    \"15\": \"B-/people/person/children\",\n",
    "    \"16\": \"B-/people/person/ethnicity\",\n",
    "    \"17\": \"B-/people/person/nationality\",\n",
    "    \"18\": \"B-/people/person/place_lived\",\n",
    "    \"19\": \"B-/people/person/place_of_birth\",\n",
    "    \"20\": \"B-/people/person/religion\",\n",
    "    \"21\": \"B-/sports/sports_team/location\",\n",
    "    \"22\": \"B-/sports/sports_team_location/teams\",\n",
    "    \"23\": \"B-LOCATION\",\n",
    "    \"24\": \"B-ORGANIZATION\",\n",
    "    \"25\": \"B-PERSON\",\n",
    "    \"26\": \"I-/business/company/advisors\",\n",
    "    \"27\": \"I-/business/company/founders\",\n",
    "    \"28\": \"I-/business/company/industry\",\n",
    "    \"29\": \"I-/business/company/major_shareholders\",\n",
    "    \"30\": \"I-/business/company/place_founded\",\n",
    "    \"31\": \"I-/business/company_shareholder/major_shareholder_of\",\n",
    "    \"32\": \"I-/business/person/company\",\n",
    "    \"33\": \"I-/location/administrative_division/country\",\n",
    "    \"34\": \"I-/location/country/administrative_divisions\",\n",
    "    \"35\": \"I-/location/country/capital\",\n",
    "    \"36\": \"I-/location/location/contains\",\n",
    "    \"37\": \"I-/location/neighborhood/neighborhood_of\",\n",
    "    \"38\": \"I-/people/deceased_person/place_of_death\",\n",
    "    \"39\": \"I-/people/ethnicity/people\",\n",
    "    \"40\": \"I-/people/person/children\",\n",
    "    \"41\": \"I-/people/person/nationality\",\n",
    "    \"42\": \"I-/people/person/place_lived\",\n",
    "    \"43\": \"I-/people/person/place_of_birth\",\n",
    "    \"44\": \"I-/people/person/religion\",\n",
    "    \"45\": \"I-/sports/sports_team/location\",\n",
    "    \"46\": \"I-/sports/sports_team_location/teams\",\n",
    "    \"47\": \"I-LOCATION\",\n",
    "    \"48\": \"I-ORGANIZATION\",\n",
    "    \"49\": \"I-PERSON\",\n",
    "    \"50\": \"O\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6c017f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logic_dist(probs, labels, query_ids, label2id, id2label, hard_rule):\n",
    "    dr_loss = []\n",
    "    # probs: B X T X H, labels: B X T, query_ids: B X 1\n",
    "    for prob, label, query_id in zip(probs, labels, query_ids):\n",
    "        dr, isGround = 1, False\n",
    "        for idx, label_id in enumerate(label):\n",
    "            IOB_tag = id2label[str(label_id)]\n",
    "            if \"B-/\" in IOB_tag: # relation tag (l2)\n",
    "                re_id, ent_id = label2id[IOB_tag], label2id['B-'+hard_rule[IOB_tag[2:]]]\n",
    "                dt = max(prob[idx][re_id] - prob[query_id[0]][ent_id], 0)\n",
    "                dr = min(dt, dr)\n",
    "                isGround = True\n",
    "        if not isGround:\n",
    "            dr = 0\n",
    "            \n",
    "        dr_loss.append(dr\n",
    "        \n",
    "    return torch.sum(torch.Tensor(dr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4f3a29ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50, 23, 47, 50, 50, 50, 10, 50], [50, 24, 48, 48, 50, 50, 50, 50], [50, 50, 50, 50, 50, 50, 25, 50], [50, 15, 50, 50, 25, 50, 7, 33], [50, 50, 50, 24, 50, 50, 50, 50], [50, 50, 50, 50, 50, 50, 23, 47], [50, 24, 50, 50, 50, 50, 50, 50], [50, 50, 50, 50, 50, 50, 50, 25], [50, 50, 23, 50, 50, 50, 50, 50], [24, 50, 50, 50, 50, 50, 50, 50]]\n",
      "[[1], [1], [6], [4], [3], [6], [1], [7], [2], [0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0167)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, H = 10, 8, 51\n",
    "logits = torch.rand(B, T, H)\n",
    "m = nn.Softmax(dim=-1)\n",
    "probs = m(logits) # B X T X H\n",
    "# print(probs[0])\n",
    "labels = [[H-1] * T for _ in range(B)]\n",
    "labels[0][1] = 23\n",
    "labels[0][2] = 47\n",
    "labels[0][6] = 10\n",
    "labels[1][1] = 24\n",
    "labels[1][2] = 48\n",
    "labels[1][3] = 48\n",
    "labels[2][6] = 25\n",
    "labels[3][1] = 15\n",
    "labels[3][4] = 25\n",
    "labels[3][6] = 7\n",
    "labels[3][7] = 33\n",
    "labels[4][3] = 24\n",
    "labels[5][6] = 23\n",
    "labels[5][7] = 47\n",
    "labels[6][1] = 24\n",
    "labels[7][7] = 25\n",
    "labels[8][2] = 23\n",
    "labels[9][0] = 24\n",
    "print(labels)\n",
    "\n",
    "query_ids = [[1], [1], [6], [4], [3], [6], [1], [7], [2], [0]]\n",
    "print(query_ids)\n",
    "\n",
    "logic_dist(probs, labels, query_ids, label2id, id2label, hard_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "736d82c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentText': 'But that spasm of irritation by a master intimidator was minor compared with what Bobby Fischer , the erratic former world chess champion , dished out in March at a news conference in Reykjavik , Iceland .',\n",
       " 'articleId': '/m/vinci8/data1/riedel/projects/relation/kb/nyt1/docstore/nyt-2005-2006.backup/1677367.xml.pb',\n",
       " 'relationMentions': [{'em1Text': 'Bobby Fischer',\n",
       "   'em2Text': 'Iceland',\n",
       "   'label': '/people/person/nationality'},\n",
       "  {'em1Text': 'Iceland',\n",
       "   'em2Text': 'Reykjavik',\n",
       "   'label': '/location/country/capital'},\n",
       "  {'em1Text': 'Iceland',\n",
       "   'em2Text': 'Reykjavik',\n",
       "   'label': '/location/location/contains'},\n",
       "  {'em1Text': 'Bobby Fischer',\n",
       "   'em2Text': 'Reykjavik',\n",
       "   'label': '/people/deceased_person/place_of_death'}],\n",
       " 'entityMentions': [{'start': 0, 'label': 'PERSON', 'text': 'Bobby Fischer'},\n",
       "  {'start': 1, 'label': 'LOCATION', 'text': 'Reykjavik'},\n",
       "  {'start': 2, 'label': 'LOCATION', 'text': 'Iceland'}],\n",
       " 'sentId': '1'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "833c458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('NYT/joint_test_NYT.json', 'r')\n",
    "data = []\n",
    "for line in f.readlines():\n",
    "    data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e522817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\n",
    "    {'d': [1,2,6,7], 'b':[5,0,3,1,2,3,4,3,5]},\n",
    "    {'d': [4,2,9], 'b': [1,8,2]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5c320e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'d': [4, 2, 9], 'b': [1, 8, 2]}]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in a if len(s['b']) <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "159f6813",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort(key=lambda x: len(x['d']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2cea9601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'d': [4, 2, 9], 'b': [1, 8, 2]},\n",
       " {'d': [1, 2, 6, 7], 'b': [5, 0, 3, 1, 2, 3, 4, 3, 5]}]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688af207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
